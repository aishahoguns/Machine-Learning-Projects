{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfbef159-b194-4d16-9950-30d92b966298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6632eeea-b953-4b78-80ce-ca3b42cbc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17f3da32-1304-4b99-a5a6-857fcc343c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv_data = np.loadtxt('Audiobooks_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4edf2ab7-9d67-44c3-b9ad-b9ee7ad8a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "unscaled_targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a67020-cac2-4943-b51f-07b726509865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26fd3158-2d23-40cf-94bd-ea0e9d38b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(unscaled_targets_all))\n",
    "targets_we_do_not_need = []\n",
    "zero_targets_count = 0\n",
    "for i in range(unscaled_targets_all.shape[0]):\n",
    "    if unscaled_targets_all[i] == 0:\n",
    "        zero_targets_count +=1\n",
    "        if zero_targets_count > num_one_targets:\n",
    "            targets_we_do_not_need.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b778fb-6b40-4c03-af8a-57d175fb4fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2af968f-dbe2-422f-87dd-ea34b8fa1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs = np.delete(unscaled_inputs_all,targets_we_do_not_need, axis = 0)\n",
    "unscaled_targets = np.delete(unscaled_targets_all,targets_we_do_not_need, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce0e029d-3f8c-4fc3-a9d2-2f8bc34a1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_balanced_prior = unscaled_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3818128-7015-41bc-a202-8c1c7efaa0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_balanced_prior.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09bb6380-f124-4fbe-b95c-529b90876ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018fd8de-4788-44ca-be11-4598b83fea43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce897c-c3e4-43da-ab7f-949da0c6175b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e37ad070-c4ff-46ad-9618-9817cc765e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6421c8d8-081f-4906-9bd2-aad44bb6dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86ed9dda-9cd7-44c3-9c5c-87bfd10dad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_balanced_prior[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a303889-8785-463e-87dd-1a972b26b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##split_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "121a7113-377b-497f-bfa8-487fc98a92d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784.0 3579 0.4984632578932663\n",
      "225.0 447 0.5033557046979866\n",
      "228.0 448 0.5089285714285714\n"
     ]
    }
   ],
   "source": [
    "input_size = shuffled_inputs.shape[0]\n",
    "train_inputs_size = int(0.8*input_size)\n",
    "validation_inputs_size = int(0.1*input_size)\n",
    "test_inputs_size = input_size - train_inputs_size-validation_inputs_size\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_inputs_size]\n",
    "train_targets = shuffled_targets[:train_inputs_size]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_inputs_size:train_inputs_size + validation_inputs_size]\n",
    "validation_targets =shuffled_targets[train_inputs_size:train_inputs_size + validation_inputs_size]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_inputs_size + validation_inputs_size:]\n",
    "test_targets = shuffled_targets[train_inputs_size + validation_inputs_size:]\n",
    "\n",
    "print(np.sum(train_targets), train_inputs_size, np.sum(train_targets) /train_inputs_size)\n",
    "print(np.sum(validation_targets), validation_inputs_size, np.sum(validation_targets) / validation_inputs_size)\n",
    "print(np.sum(test_targets), test_inputs_size, np.sum(test_targets) / test_inputs_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ffe4aa0-a544-4cc7-b30b-5d0c503032af",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train_1', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation_1', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test_1', inputs=test_inputs, targets=test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
